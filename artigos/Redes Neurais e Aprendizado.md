# Como Redes Neurais Artificiais Aprendem Através de Experiência

Artigo original de [Geoffrey Everest Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton).

Traduzido por [Gabriel Felippe](https://akiradev.netlify.app).

Redes de neurônios artificiais podem aprender a representar informações complicadas. Tais redes neurais podem prover intuições sobre as habilidades de aprendizado do cérebro humano.

O cérebro é um notável computador. Ele é capaz de interpretar informação imprecisa através dos sentidos em uma taxa incrivelmente rápida. Ele é capaz de discernir um sussurro em uma sala barulhenta, uma face em um local pouco iluminado e uma agenda oculta em uma declaração política. O mais impressionante de tudo, o cérebro aprende - sem instruções explícitas - a criar as representações internas que tornam essas habilidades possíveis. 

Muito ainda é desconhecido sobre como o cérebro treina a si mesmo a processar informação, então abundam as teorias. Para testar essas hipóteses, meus colegas e Eu tentamos imitar os processos de aprendizado do cérebro através da criação de redes de neurônios artificiais. Nós contruímos essas redes neurais tentando primeiro deduzir as características essenciais dos neurônios e suas interconexões. Nós então tipicamente programamos um computador para simular essas características.

Pelo fato de nosso conhecimento sobre os neurônios ser incompleto e nosso poder computacional limitado, nossos modelos são necessariamente idealizações grosseiras de redes de neurônios reais. Naturalmente, nós debatemos com entusiasmo quais características são mais essenciais na simualação de neurônios. Ao testarmos essas características em redes neurais artificiais, nós obtivemos sucesso em descartar todos os tipos de teorias sobre como o cérebro processa informação. Os modelos também estão começando a revelar como o cérebro possivelmente realiza sua notável característica de aprendizado.

No cérebro humano, um típico neurônio coleta sinais de outros através de um *host* de estruturas finas chamado dendritos. O neurônio envia picos de atividade elétrica através de um fio longo e fino conhecido como axônio, que se divide em milhares de ramos. No fim de cada ramo, uma estrutura chamada sinapse converte a atividade do axônio em efeitos elétricos que inibem ou excitam atividade nos neurônios conectados. Quando um neurônio recebe um *input* excitatório que é suficientemente grande comparado com seu *input* inibitório, ele envia um pico de atividade elétrica através de seu axônio. Aprendizado ocorre na alteração da eficácia das sinapses de forma que a influência de um neurônio sob outro mude.

Redes neurais artificiais são tipicamente compostas de 'unidades' interconectadas que servem como neurônios modelo. A função da sinapse é modelada por um peso modificável, no qual é associado com cada conexão. A maioria das redes neurais artificiais não refletem a geometria detalhada dos dendritos e axônios, e elas expressam o *output* elétrico de um neurônio como um único número que representa a taxa de disparo - sua atividade.

Cada unidade converte o padrão de atividades recebidas que ele recebe em uma única atividade de saída que ele transmite para outras unidades. Ele executa essa conversão em dois estágios. Primeiro, ele multiplica cada atividade recebida pelo peso na conexão e acrescenta todos esses inputs pesados para obter a quantidade chamada de *input* total. Segundo, uma unidade usa uma função *input-output* que transforma o *input* total em uma atividade de saída.

O comportamento de uma rede neural artificial depende dos pesos e da função *input-output* que é especificada para as unidades. Essa função normalmente se encontra em uma de três categorias: linear, limite ou sigmoid. Para unidades lineares, a atividade de saída é proporcional ao input pesado total. Para unidades limite, a saída é definida em um dos dois níveis, dependendo se o *input* total é maior que ou menor que algum valor limite. Para unidades sigmoid, o *output* varia continuamente porém não linearmente conforme o *input* muda. Unidades sigmoid suportam uma maior semelhança à neurônios reais do que unidades lineares ou limite, porém todos os três devem ser considerados aproximações aproximadas.

Para fazer uma rede neural que execute uma tarefa específica, nós devemos escolher como as unidades são conectadas umas com as outras, e nós devemos definir os pesos nas conexões apropriadamente. As conexões determinam se é possível uma unidade influenciar a outra. Os pesos especificam a força da influência.

O mais comum tipo de rede neural artificial consiste de três grupos, ou camadas, de unidades: uma camada de unidades de *input* é conectada a uma camada de unidades "ocultas", pelo qual está conectada a uma camada de unidades de *output*. A atividade das unidades de *input* representa a informação bruta que é alimentada na rede. A atividade de cada unidade oculta é determinada pelas atividades das unidades de *input* e dos pesos sob as conexões entre o *input* e as unidades ocultas. Similarmente, o comportamente das unidades de *output* dependem da atividade das unidades ocultas e dos pesos entre unidades oculta e de *output*. 

Esse tipo simples de rede é interessante porque as unidades ocultas são livres para construírem suas próprias representações do *input*. Os pesos entre o *input* e as unidades ocultas determinam quando cada unidade oculta está ativa, e assim modificando esses pesos, uma unidade oculta pode escolher o que representa.

Nós podemos ensinar uma rede de três camadas a executar uma tarefa particular ao usarmos o seguinte procedimento. Primeiro, nós apresentamos a rede com exemplos de treinamento, que consistem de um padrão de atividades para as unidades de *input* juntamente com os padrões de atividades desejados para as unidades de *output*. Nós então determinamos quão perto o real *output* da rede corresponde com o *output* desejado. Em seguida nós alteramos o peso de cada conexão de forma que a rede produza uma melhor aproximação do *output* desejado.

Por exemplo, imagine que desejamos que a rede reconheça dígitos escritos a mão. Nós podemos utilizar um *array* de, digamos, 256 sensores, cada um registrando a presença ou ausência de tinta em uma pequena área de um único dígito. A rede então precisará de 256 unidades de *input* (uma para cada sensor), 10 unidades de *output* (um para cada tipo de dígito) e um número de unidades ocultas. Para cada tipo de dígito registrado pelos sensores, a rede deve produzir alta atividade na apropriada unidade de *output* e baixa atividade em outras unidades de *output*.

Para treinar a rede, nós apresentamos uma imagem de um dígito e comparamos a atividade real das 10 unidades de *output* com a atividade desejada. Nós então calculamos o erro, no qual é definido como o quadrado da diferença entre as atividades real e desejada. Em seguida nós alteramos o peso de cada conexão de forma a reduzir o erro. Nós repetimos esse processo de treinamento para muitas diferentes imagens de cada tipo de dígito até que a rede classifique cada imagem corretamente.

Para implementar esse procedimento, nós precisamos alterar cada peso por uma quantidade que é proporcional à taxa no qual o erro muda à medida que o peso é alterado. Essa quantidade - chamada de derivada de erro para o peso, ou simplesmente EW - é complicado de computar eficientemente. Uma maneira de calcular o EW é perturbar o peso levemente e observa o quanto o erro altera. Porém esse método é ineficiente porque requer uma perturbação separada para cada um dos muitos pesos.

Por volta de 1974 Paul J. Webos inventou um procedimento muito mais eficiente para calcular o EW enquanto ele estava trabalhando em direção ao doutorado na Universidade Harvard. O procedimento, agora conhecido como algoritmo back-propagation se tornou uma das ferramentas mais importantes para o treinamento de redes neurais.

O algoritmo back-propagation é mais fácil de compreender se todas as unidades na rede são lineares. O algoritmo computa cada EW primeiramente computando o EA, a taxa pelo qual o erro muda à medida que o nível de atividade de uma unidade é alterado. Para unidades de *output*, o EA é simplesmente a diferença entre o *output* real e o desejado. Para computar o EA para uma unidade oculta na camada logo antes da camada de *output*, nós primeiro identificamos todos os pesos entre essa unidade oculta e as unidades de *output* pelo qual ela está conectada. Nós então multiplicamos esses pesos pelos EA's dessas unidades de *output* e adicionamos os produtos. Essa soma é igual o EA para a unidade oculta escolhida. Depois de calcular todos os EA's na camada oculta logo antes da camada de *output*, nós podemos computar da mesma forma os EA's para outras camadas, movendo de camada para camada em uma direção oposta à maneira como as atividades se propagam pela rede. É isso que dá back-propagation seu nome. Uma vez que o EA foi computado para uma unidade, é direto ao ponto computar o EW para cada conexão de entrada da unidade. O EW é o produto do EA e da atividade através da conexão de entrada.

Para unidades não-lineares, o algoritmo back-propagation inclui um passo extra. Antes de *back-propagating*, o EA deve ser convertido em EI, a taxa pelo qual o erro muda à medida que a entrada total recebida por uma unidade é alterada.

O algoritmo back-propagation foi amplamente ignorado por anos depois de sua invenção, provavelmente porque sua utilidade não foi totalmente apreciada. No começo de 1980 David E. Rumelhart em San Diego e David B. Parker, então na Universidade Stanford, independentemente redescobriram o algoritmo. Em 1986 Rumelhart, Ronald J. Williams, também na Universidade da Califórnia em San Diego, e Eu popularizamos o algoritmo através da demonstração que ele pode ensinar as unidades ocultas a produzir interessantes representações de padrões de *input* complexos.

O algoritmo back-propagation se provou surpreendentemente bom no treinamento de redes neurais com múltiplas camadas para executar uma grande variedade de tarefas. É mais útil em situações no qual a relação entre o *input* e *output* é não-linear e os dados de treinamento são abundantes. Ao aplicar o algoritmo, pesquisadores produziram redes neurais que reconhecem dígitos manuscritos, preveêm taxas de câmbio de moedas e maximizam os rendimentos dos processos químicos. Eles até mesmo usaram o algoritmo para treinar redes que identificam células pré-cancerígenas em exames de Papanicolaou e que ajustem o espelho de um telescópio para cancelar distorções atmosféricas.

Dentro do campo da neurociência, Richard Andersen do Massachusetts Institute of Technology e David Zipser da Universidade da Califórnia em San Diego mostram que o algoritmo back-propagation é uma ferramenta útil para explicar a função de alguns neurônios no córtex cerebral. Eles treinaram uma rede neural para responder a estímulos visuais utilizando back propagation. Eles então descobriram que as respostas das unidades ocultas eram notavelmente semelhantes aos dos neurônios reais responsáveis pela conversão de informação visual da retina em uma forma adequada para áreas visuais profundas do cérebro.

Ainda o algoritmo back propagation teve uma recepção bastante mista como teoria de como neurônios biológicos aprendem. Por um lado, o algoritmo back propagation fez uma contribuição valorosa em um nível abstrato. O algoritmo é muito bom na criação de representações sensíveis em unidades ocultas. Como resultado, pesquisadores adquiriram confiança no aprendizado de procedimentos no qual pesos são gradualmente ajustados para reduzir erros. Anteriormente muitos trabalhadores assumiram que tais métodos seriam inúteis porque eles inevitavelmente levariam a otimizados localmente porém soluções terríveis globalmente.

Por exemplo, uma rede de reconhecimento dígitos pode consistentemente alojar-se em um conjunto de pesos que torna a rede confundir um's e sete's mesmo que exista um conjunto ideal de pesos que permita à rede discriminar entre os dígitos. Esse medo suportou uma crença difundida que um procedimento de aprendizado só era interessante se fosse garantido que convergisse para uma solução globalmente ideal. Back propagation mostrou que para muitas tarefas a convergência global não era necessária para alcançar uma perfomance boa.

Por outro lado, back propagation parece biologicamente implausível. A mais óbvia dificuldade é que informação deve viajar através das mesmas conexões na direção reversa, de uma camada para a camada anterior. Claramente, isso não ocorre em neurônios reais. Porém essa objeção é na verdade superficial. O cérebro possui muitos caminhos das camadas posteriores para as anteriores, e ele pode utilizar esses caminhos de diversas maneiras para conver a informação necessária para o aprendizado.

Um problema mais importante é a velocidade do algoritmo back propagation. Aqui a questão central é como o tempo necessário para aprender aumenta conforme a rede aumenta de tamanho. O tempo consumido para calcular as derivadas de erro para os pesos em um determinado exemplo de treinamento é proporcional ao tamanho da rede porque a quantidade de computação é proporcional ao número de pesos. Porém redes maiores tipicamente exigem mais exemplos de treinamento e elas devem atualizar os pesos mais vezes. Consequentemente, o tempo de aprendizado cresce muito mais rápido do que o tamanho da rede.

A mais séria objeção ao back propagation como modelo de aprendizado real é que ele requer um professor para fornecer o *output* desejado para cada exemplo de treinamento. Em contraste, pessoas aprendem a maioria das coisas sem a ajuda de um professor. Ninguém nos apresenta com uma detalhada descrição das representações internas do mundo que nós devemos aprender para extrair do nosso *input* sensorial. Nós aprendemos a entender sentenças ou cenas visuais sem nenhuma instrução direta.

Como pode uma rede aprender representações internas apropriadas se ela inicia sem nenhum conhecimento e nenhum professor? Se uma rede é apresentada com um grande conjunto de padrões porém não é dado a ela informação sobre o que fazer com eles, ela aparentemente não possui um problema bem-definido para resolver. Mesmo assim, pesquisadores desenvolveram diversos procedimentos não-supervisionados de propósito geral que podem ajustar os pesos na rede apropriadamente.

Todos esses procedimentos compartilham duas características: eles apelam, implícita ou explicitamente para alguma noção da qualidade da representação e eles trabalham alterando os pesos para aperfeiçoar a qualidade da representação extraída pelas unidades ocultas.

Em geral, uma boa representação é uma que pode ser descrita muito economicamente mas mesmo assim contém informação suficiente que permite uma aproximação aproximada do *input* bruto a ser reconstruído. Por exemplo, considere uma imagem consistindo de várias elipses. Suponha que um dispositivo traduza a imagem em um array de milhões de quadrados pequeninos, cada um no qual é claro ou escuro. A imagem pode ser representada simplesmente pelas posições dos quadrados escuros. Porém, outras representações mais eficientes também são possíveis. As elipses diferem em apenas cinco maneiras: orientação, posição vertical, posição horizontal, comprimento e largura. Uma imagem pode portanto ser descrita utilizando apenas cinco parâmetros por elipse.

Embora a descrição de uma elipse por cinco parâmetros requerer mais bits do que descrever um único quadrado escuro por duas coordenadas, nós obtemos uma economia global porque muito menos parâmetros são necessários do que coordenadas. Além disso, nós não perdemos nenhuma informação ao descrever elipses em termos dos seus parâmetros: dados os parâmetros da elipse nós podemos reconstruir a imagem original se quisermos.

Quase todo procedimento de aprendizado não-supervisionado pode ser visto como métodos de minimizar a soma de dois termos, um custo de código e um custo de reconstrução. O custo de código é o número de bits requerido para descrever as atividades das unidades ocultas. O custo de reconstrução é o número de bits necessário para descrever o desajuste entre o *input* bruto e a melhor aproximação a ele que pode ser reconstruída das atividades das unidades ocultas. O custo de reconstrução é proporcional a diferença ao quadrado entre o *input* bruto e sua reconstrução.

Dois métodos simples para descobrir códigos econômicos permitem reconstrução bastante precisa do *input*: Aprendizagem dos componentes-principais e aprendizado competitivo. Em ambas abordagens, primeiro decidimos quão econômico o código deve ser e então modificamos os pesos na rede para minimizar o erro de reconstrução.

Uma estratégia de aprendizagem dos componentes-principais é baseado na ideia de que se as atividades de pares de unidades de *input* estão correlacionadaos de alguma maneira, é uma desperdício de bits descrever cada atividade de *input* separadamente. Uma abordagem mais eficiente é extrair e descrever os componentes principais - isto é, os componentes da variação compartilhados por muitas unidades de *input*. Se nós desejarmos descobrir, digamos, 10 dos componentes principais, então nós precisamos apenas de uma única camada de 10 unidades ocultas.

Porque essas redes representam o *input* usando apenas um pequeno número de componentes, o custo de código é baixo. E porque o *input* pode ser reconstruído muito bem através dos componentes principais, o custo de reconstrução é pequeno.

Uma maneira de treinar esse tipo de rede é forçar ela a reconstruir uma aproximação ao *input* de um conjunto de unidades de *output*. Então back propagation pode ser utilizado para minimizar a diferença entre o *output* real e o *output* desejado. Esse processo se assemelha ao aprendizado supervisionado, porém porque o *output* desejado é exatamente o mesmo que o *input*, nenhum professor é necessário.

Muitos pesquisadores, incluindo Ralph Linsker do Centro de Pesquisa IBM Thomas J. Watson e Erkki Oja da Universidade de Tecnologia Lappeenranta na Finlândia descobriram algoritmos alternativos para aprender os componentes principais. Esses algoritmos são mais plausíveis biologicamente porque eles não exigem unidades de *output* ou back propagation. Em vez disso eles usam a correlação entre a atividade de uma unidade oculta e a atividade de uma unidade de *input* para determinar a mudança no peso.

Quando uma rede neural usa aprendizado de componentes-principais, um pequeno número de unidades ocultas cooperam em representar o padrão de *input*. Em contraste, no aprendizado competitivo, um grande número de unidades ocultas competem de forma que uma única unidade oculta é usada para representar qualquer padrão de *input* particular. A selecionada unidade oculta é aquela cujos pesos recebidos são mais semelhantes ao padrão de *input*.

Agora, suponha que tivemos que reconstruir o padrão de *input* unicamente pelo nosso conhecimento dos quais a unidade oculta foi escolhida. Nossa melhor aposta seria copiar o padrão de pesos recebidos da unidade oculta escolhida. Para minimzar o erro de reconstrução, nós devemos mover o padrão de pesos da unidade oculta vitoriosa ainda mais perto do padrão de entrada. É isso que a aprendizagem competitiva faz. Se a rede é apresentada com dados de treinamento que pode ser agrupados em clusters de padrões de *input* similares, cada unidade oculta aprende a representar um diferente cluster, e seus pesos recebidos convergem para o centro do cluster.

Como o algoritmo de componentes-principais, o aprendizado competitivo minimiza o custo de reconstrução mantendo o custo do código baixo. Nós podemos nos dar o luxo de usar muitas unidades ocultas porque mesmo com um milhão de unidades são necessários apenas 20 bits para dizer qual venceu.

No começo dos anos 80 Teuvo Kohonen da Universidade de Helsinki introduziu uma modificação importante no algoritmo de aprendizado competitivo. Kohonen mostrou como fazer unidades ocultas fisicamente adjacentes aprenderem a representar padrões de *input* similares. O algoritmo de Kohonen adapta não apenas os pesos da unidade oculta vitoriosa mas também o peso dos vizinhos vencedores. A habilidade do algoritmo de mapear padrões de *inputs* similares para unidades ocultas próximas sugere que um procedimento desse tipo pode ser o que o cérebro utiliza para criar mapas topográficos encontrados no córtex visual.

Algoritmos de aprendizado não-supervisionado podem ser classificados de acordo com o tipo de representação que eles criam. Em métodos de componentes-principais, as unidades ocultas cooperam, e a representação de cada padrão de *input* é distribuída por todos eles. Em métodos competitivos, as unidades ocultas competem, e a representação do padrão de *input* é localizada na única unidade oculta que é selecionado. Até recentemente, a maioria dos trabalhos em aprendizado não-supervisionado focaram em uma ou outra dessas duas técnicas, provavelmente porque elas levam a regras simples para mudar os pesos. Porém os mais interessantes e poderosos algoritmos provavelmente estão em algum lugar entre os extremos de representações puramente distribuída e puramente localizada.

Horace B. Barlow da Universidade de Cambridge propôs um modelo no qual cada unidade oculta raramente está ativa e a representação de cada padrão de *input* é distribuída por um pequeno número de unidades ocultas selecionadas. Ele e seus colegas mostraram que esse tipo de código pode ser aprendido forçando unidades ocultas a não serem correlacionadas garantindo também de que o código oculto permita uma boa reconstrução do *input*.

Infelizmente, a maioria dos métodos atuais de minimizar o custo do código tendem a eliminar toda a redundância entre as atividades das unidades ocultas. Como resultado, a rede é muito sensível ao mau funcionamento de uma única unidade oculta. Esse recurso não é característico do cérebro, no qual é geralmente não muito afetado pela perda de alguns neurônios.

O cérebro parece utilizar o que é conhecido como códigos populacionais, no qual informação é representada por toda uma população de neurônios ativos. Esse ponto foi belamente demonstrado nos experimentos de David L. Sparks e seus colegas na Universide do Alabama. Enquanto investigava como o cérebro de um macaco instrui seus olhos para onde mover, eles encontraram que o movimento requerido é codificado pelas atividades de uma população inteira de células, cada uma no qual representa um movimento um pouco diferente. O movimento do olho que é realmente feito corresponde à média de todos os movimentos codificados pelas células ativas. Se algumas células do cérebro são anestesiadas, o olho move para o ponto associado com a média das células ativas restantes. Códigos populacionais podem ser usados para codificar não apenas movimentos de olho mas também de faces, como mostrado por Malcolm P. Young e Shigeru Yamane no Instituto RIKEN no Japão em experimentos recentes no córtex temporal inferior de macacos.

Para ambos os movimentos dos olhos e faces, o cérebro deve representar entidades que variam ao longo de diferentes dimensões. No caso de um movimento do olho, existem apenas duas dimensões, porém para algo como uma face, existem dimensões como felicidade, aspecto do cabelo ou familiaridade, bem como parâmetros espaciais como posição, tamanho e orientação. Se associarmos com cada célula sensível ao rosto os parâmetros da face que o tornam mais ativo, nós podemos tomar a média desses parâmetros sob uma população de células ativas para descobrir o parâmetro da face sendo representado por esse código populacional. Em termos abstratos, cada célula da face representa um ponto particular em um espaço multidimensional de faces possíveis, e qualquer face pode então ser representada pela ativação de todas as células que codificam faces muito similares, para que um aumento de atividade apareça no espaço multidimensional de possíveis faces.

Codificação populacional é atrativa porque funciona mesmo que alguns neurônios sejam danificados. Pode ser feito porque a perda de um subconjunto aleatório de neurônios tem pouco impacto na população média. O mesmo raciocínio é aplicado se alguns neurônios são negligenciados quando o sistema está em apuros. Neurônios se comunicam através do envio discreto de picos chamado potenciais de ação e em um muito curto intervalo de tempo muitos dos neurônios "ativos" podem não ter tempo para enviar um pico. Mesmo assim, em um intervalo tão curto, um código populacional em uma parte do cérebro pode ainda dar origem a um código de população aproximadamente correto em outra parte do cérebro.

À primeira vista, a redundância nos códigos de população parece incompatível com a ideia de construir representações internas que minimizam o custo de código. Felizmente nós podemos superar essa dificuldade ao usar uma medida menos direta do custo do código. Se a atividade que codifica uma entitade particular é uma colisão suave no qual a atividade diminui em uma maneira padrão conforme nós nos distanciamos do centro, nós podemos descrever o inchaço de atividade completamente meramente ao especificar seu centro. Portanto, uma medida mais justa do custo do código é o custo de descrever o centro do inchaço da atividade mais o custo de descrever como as atividades reais das unidades afastam-se da desejada colisão suave de atividade.

Usando essa medida do custo de código, nós encontramos que códigos populacionais são uma maneira conveniente de extrair uma hierarquia de codificações progressivamente mais eficientes do *input* sensorial. Esse ponto é melhor ilustrado por um simples exemplo. Considera uma rede neural que é apresentada com uma imagem de uma face. Suponha que a rede já contém um conjunto de unidades dedicadas a representar narizes, outro conjunto para bocas e outro conjunto para olhos. Quando lhe é mostrado uma face particular, haverá um inchaço de atividade nas unidades de nariz, uma nas unidades de boca e duas nas unidades de olhos. A localização de cada uma desses inchaços de atividades representam os parâmetros espaciais da características codificada pelo inchaço. Descrevendo os quatro inchaços de atividade é menos custoso do que descrever a imagem cru, mas seria obviamente menos custoso descrever um único inchaço de atividade em um conjunto de unidades de face, assumindo é claro que o nariz, boca e olhos estão nas corretas relações espaciais para formar uma face.

Isso levanta uma questão interessante: Como pode a rede checar que as partes estão corretamente relacionados umas com as outras para construir uma face? Algum tempo atrás Dana H. Ballard da Universidade de Rochester introduziu uma inteligente técnica para resolver esse tipo de problema que funciona perfeitamente com códigos populacionais.

Se nós conhecermos a posição, tamanho e orientação do nariz, nós podemos prever a posição, tamanho e orientação da face pelo qual ela pertence porque a relação espacial entre narizes e faces é aproximadamente fixada. Nós então definimos os pesos na rede neural de forma que um inchaço de atividade nas unidades de nariz tente causar um inchaço de atividade adequadamente relacionado nas unidades de face. Porém, nós também definimos os limiares das unidades de face de forma que as unidades de nariz sozinhas são insuficientes para ativar as unidades de face. Se, entretanto, o inchaço de atividade nas unidades de boca também tentarem causar um inchaço no mesmo local das unidades de face, então os limiares podem ser superados. Em efeito, nós checamos que o nariz e a boca são corretamente relacionados um com o outro ao checar que ambos os dois preveem os mesmos parâmetros espaciais para toda a face. 

Este método de verificação de relações espaciais é intrigante porque ele faz uso do tipo de redundância entre diferentes partes de uma imagem que o aprendizado não-supervisionado deve ser bom em buscar. Parece, portanto natural tentar fazer o uso de aprendizado não-supervisionado para descobrir códigos populacionais hierárquicos para extração de formas complexas. Em 1986, Eric Saund do M.I.T demonstrou um método de aprender códigos simples populacionais para formas. Parece provável que com uma definição clara do custo de código, uma rede não-supervisionada estará apta a descobrir hierarquias mais complexas ao tentar minimizar o custo de codificar a imagem. Richard Zemel e Eu na Universidade de Toronto estamos atualmente investigando essa possibilidade.

Ao utilizar o aprendizado não-supervisionado para extrair uma hierarquia de representações sucessivamente mais econômicas, deve ser possível aperfeiçoar grandemente a velocidade do aprendizado em redes grandes de múltiplas camadas. Cada camada da rede adapta seus pesos recebidos para tornar sua representação melhor do que a representação na camada anterior, então pesos em uma camada podem ser aprendidos sem referência aos pesos nas camadas subsequentes. Essa estratégia elimina muitas das interações entre pesos que tornam o aprendizado back propagation muito lento em redes de múltiplas camadas profundas.

Todos os procedimentos de aprendizado discutidos até agora são implementados em redes neurais no qual a atividade flui apenas na direção para frente, de *input* para *output* embora derivadas de erro podem fluir no sentido inverso. Outra importante possibilidade a considerar são redes no qual a atividade flui em volta de loops fechados. Tais redes recorrentes podem se estabelecer em estados estáveis, ou elas podem exibir dinâmicas temporais complexas que podem ser usadas para produzir comportamento sequencial. Se eles se estabelecerem em estados estáveis, derivadas de erro podem ser computadas utilizando métodos muito mais simples do que back propagation.

Embora investigadores criaram alguns algoritmos poderosos de aprendizado que são de grande valor prático, nós ainda não sabemos quais representações e procedimentos de aprendizado são realmente utilizados pelo cérebro. Porém cedo ou tarde estudos computacionais de aprendizado em redes neurais artificiais irão convergirem nos métodos de descoberta por evolução.

Quando isso acontecer, muitos dados empíricos diversos sobre o cérebro irão de repente fazer sentido e muitas novas aplicações de redes neurais artificiais se tornarão factíveis.